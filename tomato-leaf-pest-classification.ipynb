{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This neural network classifies images of tomato pests based on [Huang and Chuang's dataset](https://data.mendeley.com/datasets/s62zm6djd2/1). One experimental setup uses the dataset with basic augmentation and another setup uses a dataset with GAN augmentation. The model to be trained uses transfer learning on ImageNet based on a finetuned MobileNet model. MobileNet was used in order to deploy the model with greater efficiency into the field for edge computing.\n\nPlease setup datasets prior to running notebook:\n\n* [Original Dataset](https://www.kaggle.com/datasets/aprilryan/original)\n* [Dataset with Basic Augmentation](https://www.kaggle.com/datasets/aprilryan/pyaugm)\n* [Dataset with Generative Augmentation](https://www.kaggle.com/datasets/aprilryan/tomatogan)\n\n@author Jose Enrique R. Lopez<br />\n@date-created 8 November 2020","metadata":{"papermill":{"duration":0.027052,"end_time":"2021-11-27T09:45:41.26062","exception":false,"start_time":"2021-11-27T09:45:41.233568","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{"papermill":{"duration":0.021411,"end_time":"2021-11-27T09:45:41.30552","exception":false,"start_time":"2021-11-27T09:45:41.284109","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications import imagenet_utils\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport os\nimport shutil\nimport random\nimport glob\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline","metadata":{"papermill":{"duration":5.493129,"end_time":"2021-11-27T09:45:46.820525","exception":false,"start_time":"2021-11-27T09:45:41.327396","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-01T06:41:15.651898Z","iopub.execute_input":"2022-08-01T06:41:15.652291Z","iopub.status.idle":"2022-08-01T06:41:22.325219Z","shell.execute_reply.started":"2022-08-01T06:41:15.652180Z","shell.execute_reply":"2022-08-01T06:41:22.324501Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Initialize experiment components","metadata":{}},{"cell_type":"code","source":"#EXPERIMENTAL TREATMENTS/MODES\nORIGINAL = 0\nAUGMENTED = 1\nGAN = 2","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:41:22.326925Z","iopub.execute_input":"2022-08-01T06:41:22.327182Z","iopub.status.idle":"2022-08-01T06:41:22.334212Z","shell.execute_reply.started":"2022-08-01T06:41:22.327146Z","shell.execute_reply":"2022-08-01T06:41:22.333178Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# vgg16_model = tf.keras.applications.vgg16.VGG16()\nmobile = tf.keras.applications.mobilenet.MobileNet(input_shape = (128,128, 3))\n","metadata":{"papermill":{"duration":3.603412,"end_time":"2021-11-27T09:45:50.444292","exception":false,"start_time":"2021-11-27T09:45:46.84088","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-01T06:41:22.336371Z","iopub.execute_input":"2022-08-01T06:41:22.337076Z","iopub.status.idle":"2022-08-01T06:41:26.361591Z","shell.execute_reply.started":"2022-08-01T06:41:22.337040Z","shell.execute_reply":"2022-08-01T06:41:26.360805Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Utility Functions","metadata":{"papermill":{"duration":0.021452,"end_time":"2021-11-27T09:45:50.488621","exception":false,"start_time":"2021-11-27T09:45:50.467169","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    #plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], '.2f'),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"papermill":{"duration":0.033962,"end_time":"2021-11-27T09:45:50.543978","exception":false,"start_time":"2021-11-27T09:45:50.510016","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-01T06:41:26.363876Z","iopub.execute_input":"2022-08-01T06:41:26.364131Z","iopub.status.idle":"2022-08-01T06:41:26.375001Z","shell.execute_reply.started":"2022-08-01T06:41:26.364095Z","shell.execute_reply":"2022-08-01T06:41:26.373965Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"id":"1em8WJt3tzJB","papermill":{"duration":0.028384,"end_time":"2021-11-27T09:45:50.5938","exception":false,"start_time":"2021-11-27T09:45:50.565416","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-01T06:41:26.376216Z","iopub.execute_input":"2022-08-01T06:41:26.376748Z","iopub.status.idle":"2022-08-01T06:41:26.388536Z","shell.execute_reply.started":"2022-08-01T06:41:26.376687Z","shell.execute_reply":"2022-08-01T06:41:26.387771Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"classes = ['SE', 'SL', 'TU', 'BA', 'MP', 'HA']","metadata":{"papermill":{"duration":0.028148,"end_time":"2021-11-27T09:45:50.642877","exception":false,"start_time":"2021-11-27T09:45:50.614729","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-01T06:41:26.389654Z","iopub.execute_input":"2022-08-01T06:41:26.390006Z","iopub.status.idle":"2022-08-01T06:41:26.398336Z","shell.execute_reply.started":"2022-08-01T06:41:26.389969Z","shell.execute_reply":"2022-08-01T06:41:26.397515Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Retrieve Data","metadata":{"papermill":{"duration":0.021266,"end_time":"2021-11-27T09:45:51.506417","exception":false,"start_time":"2021-11-27T09:45:51.485151","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def preprocess(image):\n    rotated = np.rot90(image, np.random.choice([-1, 0, 1]))\n    preprocessed = preprocessing_function=tf.keras.applications.mobilenet.preprocess_input(image)\n    return preprocessed","metadata":{"execution":{"iopub.status.busy":"2022-08-01T06:41:26.399760Z","iopub.execute_input":"2022-08-01T06:41:26.400018Z","iopub.status.idle":"2022-08-01T06:41:26.408844Z","shell.execute_reply.started":"2022-08-01T06:41:26.399984Z","shell.execute_reply":"2022-08-01T06:41:26.408062Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"mode = ORIGINAL\n\nif mode == ORIGINAL:\n    train_path='../input/tomatopests/train'\n    valid_path='../input/tomatopests/valid'\n    test_path='../input/tomatopests/test'\nelif mode == AUGMENTED:\n    train_path='../input/pyaugm/train'\n    valid_path='../input/pyaugm/valid'\n    test_path='../input/pyaugm/test'\nelif mode == GAN:\n    train_path='../input/tomatogan/train'\n    valid_path='../input/tomatogan/valid'\n    test_path='../input/tomatogan/test'\n    \n\ntrain_batches = ImageDataGenerator(preprocessing_function=preprocess, brightness_range=[0.7, 1.3], zoom_range=[0.8, 1], channel_shift_range=10.,horizontal_flip=True, vertical_flip = True) \\\n.flow_from_directory(directory=train_path, target_size=(128, 128), classes=classes, batch_size=16)\nvalid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input) \\\n.flow_from_directory(directory=valid_path, target_size=(128,128), classes=classes, batch_size=16)\ntest_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input) \\\n.flow_from_directory(directory=test_path, target_size=(128,128), classes=classes, batch_size=16, shuffle=False)","metadata":{"id":"s8vm8BCqW09X","outputId":"10bb9399-149e-4947-c31f-d744fc2c53b0","papermill":{"duration":2.064843,"end_time":"2021-11-27T09:45:53.649979","exception":false,"start_time":"2021-11-27T09:45:51.585136","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-01T06:53:40.306596Z","iopub.execute_input":"2022-08-01T06:53:40.307422Z","iopub.status.idle":"2022-08-01T06:53:41.226624Z","shell.execute_reply.started":"2022-08-01T06:53:40.307383Z","shell.execute_reply":"2022-08-01T06:53:41.224947Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"imgs, labels = next(train_batches)\nplotImages(imgs)\nprint(labels)","metadata":{"id":"s8vm8BCqW09X","outputId":"10bb9399-149e-4947-c31f-d744fc2c53b0","papermill":{"duration":2.064843,"end_time":"2021-11-27T09:45:53.649979","exception":false,"start_time":"2021-11-27T09:45:51.585136","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-01T06:41:36.764125Z","iopub.execute_input":"2022-08-01T06:41:36.764395Z","iopub.status.idle":"2022-08-01T06:41:37.501917Z","shell.execute_reply.started":"2022-08-01T06:41:36.764360Z","shell.execute_reply":"2022-08-01T06:41:37.501167Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Build MobileNet Model","metadata":{}},{"cell_type":"code","source":"x = mobile.layers[-6].output\noutput = Dense(units=6, activation='softmax')(x)\nmodel = Model(inputs=mobile.input, outputs=output)\n\nfor layer in model.layers[:-23]:\n    layer.trainable = False\n\nfor layer in model.layers[:10]:         \n    layer.trainable = False\n\nmodel.summary()\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode ='min', patience = 2, verbose=0)","metadata":{"id":"s8vm8BCqW09X","outputId":"10bb9399-149e-4947-c31f-d744fc2c53b0","papermill":{"duration":2.064843,"end_time":"2021-11-27T09:45:53.649979","exception":false,"start_time":"2021-11-27T09:45:51.585136","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-01T06:45:42.600298Z","iopub.execute_input":"2022-08-01T06:45:42.601019Z","iopub.status.idle":"2022-08-01T06:45:42.683571Z","shell.execute_reply.started":"2022-08-01T06:45:42.600981Z","shell.execute_reply":"2022-08-01T06:45:42.682860Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Train MobileNet model","metadata":{}},{"cell_type":"code","source":"model.fit(x=train_batches,\nepochs=20,\nsteps_per_epoch=len(train_batches),\nvalidation_data=valid_batches,\nvalidation_steps=len(valid_batches),\nverbose=2,\ncallbacks = [callback]\n)","metadata":{"id":"s8vm8BCqW09X","outputId":"10bb9399-149e-4947-c31f-d744fc2c53b0","papermill":{"duration":2.064843,"end_time":"2021-11-27T09:45:53.649979","exception":false,"start_time":"2021-11-27T09:45:51.585136","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-01T06:53:50.289293Z","iopub.execute_input":"2022-08-01T06:53:50.289860Z","iopub.status.idle":"2022-08-01T06:54:04.813225Z","shell.execute_reply.started":"2022-08-01T06:53:50.289822Z","shell.execute_reply":"2022-08-01T06:54:04.812519Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate model","metadata":{}},{"cell_type":"code","source":"modes = {0: \"CONTROL\", 1: \"AUGMENTED\", 2: \"GAN\"}\nprint(f\"**************RESULTS FOR {modes[mode]} SETUP**************\")\npredictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)\nnp.round(predictions)\nprint(\"Evaluate on test data\")\nresult = model.evaluate(test_batches, batch_size=32)\nprint(\"test loss, test acc:\", result)\n    \ncm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))\nplot_confusion_matrix(cm=cm, classes=classes, title='Confusion Matrix')","metadata":{"id":"s8vm8BCqW09X","outputId":"10bb9399-149e-4947-c31f-d744fc2c53b0","papermill":{"duration":2.064843,"end_time":"2021-11-27T09:45:53.649979","exception":false,"start_time":"2021-11-27T09:45:51.585136","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-01T06:58:25.405370Z","iopub.execute_input":"2022-08-01T06:58:25.405647Z","iopub.status.idle":"2022-08-01T06:58:26.359239Z","shell.execute_reply.started":"2022-08-01T06:58:25.405617Z","shell.execute_reply":"2022-08-01T06:58:26.358373Z"},"trusted":true},"execution_count":24,"outputs":[]}]}