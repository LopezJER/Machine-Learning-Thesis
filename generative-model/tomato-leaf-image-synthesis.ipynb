{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# WGAN tomato - 64x64","metadata":{}},{"cell_type":"markdown","source":"Import libraries","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\nimport os\nimport time\nimport datetime\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torchvision.utils as utils\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom PIL import Image\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-04-06T10:59:54.533156Z","iopub.execute_input":"2022-04-06T10:59:54.533461Z","iopub.status.idle":"2022-04-06T10:59:56.103749Z","shell.execute_reply.started":"2022-04-06T10:59:54.533374Z","shell.execute_reply":"2022-04-06T10:59:56.10297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set up paths","metadata":{}},{"cell_type":"code","source":"dataset_dir = '../input/tomato-leaf-diseases/Bacterial spot'\nfigures_dir = './figures/bacterial spot'\ncheckpoints_dir = './checkpoints/bacterial spot/'\ngraphs_dir = './graphs/bacterial spot'\nold_checkpoints_dir = '../input/checkpointsfin'\n\nif not(os.path.exists(figures_dir)): os.makedirs(figures_dir)\nif not(os.path.exists(checkpoints_dir)): os.makedirs(checkpoints_dir)\nif not(os.path.exists(graphs_dir)): os.makedirs(graphs_dir)\n    \nfg = open(\"g_losses.txt\", \"a\")\nfd = open(\"d_losses.txt\", \"a\")\nfe = open(\"epoch.txt\", \"a\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T10:59:56.105675Z","iopub.execute_input":"2022-04-06T10:59:56.105984Z","iopub.status.idle":"2022-04-06T10:59:56.113171Z","shell.execute_reply.started":"2022-04-06T10:59:56.105944Z","shell.execute_reply":"2022-04-06T10:59:56.112382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set up hyperparameters","metadata":{}},{"cell_type":"code","source":"workers = 2\n\nbatch_size = 64\nimage_size = 64\n\nnc = 3\nnoise_dim = 100\n\nnfg = 64\nnfd = 64\nepochs = 4001\n\ng_learning_rate = 1e-4\nd_learning_rate = 1e-4\nbeta1 = 0.5\nbeta2 = 0.999\ncritic_iterations = 5\nlambda_gp=10\n","metadata":{"execution":{"iopub.status.busy":"2022-04-06T10:59:56.114647Z","iopub.execute_input":"2022-04-06T10:59:56.115159Z","iopub.status.idle":"2022-04-06T10:59:56.124519Z","shell.execute_reply.started":"2022-04-06T10:59:56.115111Z","shell.execute_reply":"2022-04-06T10:59:56.12375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"True if you want to load the model from disk, False if you want the model to be initialized from scratch","metadata":{}},{"cell_type":"code","source":"load_model = True","metadata":{"execution":{"iopub.status.busy":"2022-04-06T10:59:56.127987Z","iopub.execute_input":"2022-04-06T10:59:56.128211Z","iopub.status.idle":"2022-04-06T10:59:56.134042Z","shell.execute_reply.started":"2022-04-06T10:59:56.128185Z","shell.execute_reply":"2022-04-06T10:59:56.133311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set up GPU device for training","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda:0')","metadata":{"execution":{"iopub.status.busy":"2022-04-06T10:59:56.135617Z","iopub.execute_input":"2022-04-06T10:59:56.136041Z","iopub.status.idle":"2022-04-06T10:59:56.143743Z","shell.execute_reply.started":"2022-04-06T10:59:56.136002Z","shell.execute_reply":"2022-04-06T10:59:56.142777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-04-06T10:59:56.145258Z","iopub.execute_input":"2022-04-06T10:59:56.145901Z","iopub.status.idle":"2022-04-06T10:59:56.881444Z","shell.execute_reply.started":"2022-04-06T10:59:56.145857Z","shell.execute_reply":"2022-04-06T10:59:56.880585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the dataset","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize(image_size),\n                                transforms.CenterCrop(image_size),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntrain_data = datasets.ImageFolder(dataset_dir, transform=transform)\n# dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms, download=True)\ndata_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=workers)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T10:59:56.884153Z","iopub.execute_input":"2022-04-06T10:59:56.884456Z","iopub.status.idle":"2022-04-06T10:59:57.169344Z","shell.execute_reply.started":"2022-04-06T10:59:56.884415Z","shell.execute_reply":"2022-04-06T10:59:57.168593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"View samples from the dataset","metadata":{}},{"cell_type":"code","source":"ds_sample = next(iter(data_loader))\n\nplt.figure(figsize=(8, 8))\nplt.axis('off')\nplt.title('Train data')\ngrid = np.transpose(utils.make_grid(ds_sample[0].to(device)[:64], padding=4, normalize=True).cpu(), (1, 2, 0))\nplt.imshow(grid)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T10:59:57.170377Z","iopub.execute_input":"2022-04-06T10:59:57.171893Z","iopub.status.idle":"2022-04-06T11:00:01.613095Z","shell.execute_reply.started":"2022-04-06T10:59:57.171849Z","shell.execute_reply":"2022-04-06T11:00:01.611418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define a method for weights initialization","metadata":{}},{"cell_type":"code","source":"def init_weights(model):\n    if model.__class__.__name__.find('Conv') != -1:\n        nn.init.normal_(model.weight, 0.0, 0.02)\n    elif model.__class__.__name__.find('BatchNorm') != -1:\n        nn.init.normal_(model.weight, 1.0, 0.02)\n        nn.init.zeros_(model.bias)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:01.614388Z","iopub.execute_input":"2022-04-06T11:00:01.61509Z","iopub.status.idle":"2022-04-06T11:00:01.621834Z","shell.execute_reply.started":"2022-04-06T11:00:01.615051Z","shell.execute_reply":"2022-04-06T11:00:01.621215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the generator network","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        \n        self.model = nn.Sequential(\n            nn.ConvTranspose2d(noise_dim, nfg*8, kernel_size=4, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(nfg*8),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(nfg*8, nfg*4, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg*4),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(nfg*4, nfg*2, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg*2),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(nfg*2, nfg, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(nfg, nc, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.Tanh()\n        )\n        \n    def forward(self, input):\n        return self.model(input)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:01.624955Z","iopub.execute_input":"2022-04-06T11:00:01.625773Z","iopub.status.idle":"2022-04-06T11:00:01.639488Z","shell.execute_reply.started":"2022-04-06T11:00:01.625702Z","shell.execute_reply":"2022-04-06T11:00:01.638761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the discriminator network","metadata":{}},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        \n        self.model = nn.Sequential(\n            nn.Conv2d(nc, nfd, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Dropout2d(0.5, inplace=False),\n            \n            nn.Conv2d(nfd, nfd*2, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.InstanceNorm2d(nfg*2, affine=True),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(nfd*2, nfd*4, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.InstanceNorm2d(nfg*4, affine=True),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(nfd*4, nfd*8, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.InstanceNorm2d(nfg*8, affine=True),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Dropout2d(0.5, inplace=False),\n            \n            nn.Conv2d(nfd*8, 1, kernel_size=4, stride=2, padding=0, bias=False),\n        )\n        \n    def forward(self, input):\n        return self.model(input)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:01.642698Z","iopub.execute_input":"2022-04-06T11:00:01.642924Z","iopub.status.idle":"2022-04-06T11:00:01.655677Z","shell.execute_reply.started":"2022-04-06T11:00:01.642893Z","shell.execute_reply":"2022-04-06T11:00:01.654891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Instantiate the generator and initialize its weights (option 1)","metadata":{}},{"cell_type":"code","source":"if load_model == False:\n    generator = Generator().to(device)\n    generator.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:01.659454Z","iopub.execute_input":"2022-04-06T11:00:01.659682Z","iopub.status.idle":"2022-04-06T11:00:01.666221Z","shell.execute_reply.started":"2022-04-06T11:00:01.659655Z","shell.execute_reply":"2022-04-06T11:00:01.665397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Instantiate the discriminator and initialize its weights (option 1)","metadata":{}},{"cell_type":"code","source":"if load_model == False:\n    discriminator = Discriminator().to(device)\n    discriminator.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:01.667579Z","iopub.execute_input":"2022-04-06T11:00:01.668096Z","iopub.status.idle":"2022-04-06T11:00:01.676278Z","shell.execute_reply.started":"2022-04-06T11:00:01.668055Z","shell.execute_reply":"2022-04-06T11:00:01.675464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the model from the disk (option 2)","metadata":{}},{"cell_type":"code","source":"if load_model == True:\n    generator = torch.load(os.path.join(old_checkpoints_dir, 'generator_new4000.pt'))\n    discriminator = torch.load(os.path.join(old_checkpoints_dir, 'discriminator_new4000.pt'))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:01.678512Z","iopub.execute_input":"2022-04-06T11:00:01.679045Z","iopub.status.idle":"2022-04-06T11:00:02.400584Z","shell.execute_reply.started":"2022-04-06T11:00:01.679006Z","shell.execute_reply":"2022-04-06T11:00:02.399837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the loss function (BinaryCrossEntropy)","metadata":{}},{"cell_type":"code","source":"# cross_entropy = nn.BCELoss()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:02.402548Z","iopub.execute_input":"2022-04-06T11:00:02.402977Z","iopub.status.idle":"2022-04-06T11:00:02.407332Z","shell.execute_reply.started":"2022-04-06T11:00:02.402938Z","shell.execute_reply":"2022-04-06T11:00:02.406501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define a noise vector to use to track progress","metadata":{}},{"cell_type":"code","source":"sample_noise = torch.randn(64, noise_dim, 1, 1, device=device)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:02.408935Z","iopub.execute_input":"2022-04-06T11:00:02.409465Z","iopub.status.idle":"2022-04-06T11:00:02.418447Z","shell.execute_reply.started":"2022-04-06T11:00:02.409424Z","shell.execute_reply":"2022-04-06T11:00:02.417636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the optimizers (Adam)","metadata":{}},{"cell_type":"code","source":"disc_optimizer = optim.Adam(discriminator.parameters(), lr=d_learning_rate, betas = (0.0, 0.9))\ngen_optimizer = optim.Adam(generator.parameters(), lr=g_learning_rate, betas=(0.0, 0.9))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:02.421091Z","iopub.execute_input":"2022-04-06T11:00:02.421425Z","iopub.status.idle":"2022-04-06T11:00:02.428495Z","shell.execute_reply.started":"2022-04-06T11:00:02.421385Z","shell.execute_reply":"2022-04-06T11:00:02.427621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define a function to plot loss","metadata":{}},{"cell_type":"code","source":"def plot_loss(gen_losses, disc_losses, epoch=None, save=False, show=True):\n    plt.figure(figsize=(10, 5))\n    plt.title('Generator and Discriminator losses')\n    plt.plot(gen_losses, label='G')\n    plt.plot(disc_losses, label='D')\n    plt.xlabel('Iteration')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    if save == True:\n        plt.savefig(os.path.join(graphs_dir, f'loss_{epoch}.jpg'))\n    if show == True:\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:02.430933Z","iopub.execute_input":"2022-04-06T11:00:02.43168Z","iopub.status.idle":"2022-04-06T11:00:02.439559Z","shell.execute_reply.started":"2022-04-06T11:00:02.43164Z","shell.execute_reply":"2022-04-06T11:00:02.438854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train both networks simultaneously","metadata":{}},{"cell_type":"code","source":"def gradient_penalty(critic, real, fake, device):\n    batch_size, C, H, W = real.shape\n    epsilon = torch.rand((batch_size, 1, 1, 1)).repeat(1, C, H, W).to(device)\n    try:\n        interpolated_images = real * epsilon + fake * (1 - epsilon)\n    except:\n        print(real.shape)\n        print(fake.shape)\n        print(epsilon.shape)\n    \n    mixed_scores = critic(interpolated_images)\n    \n    gradient = torch.autograd.grad(\n        inputs=interpolated_images,\n        outputs=mixed_scores,\n        grad_outputs=torch.ones_like(mixed_scores),\n        create_graph=True,\n        retain_graph=True,\n    )[0]\n    \n    gradient = gradient.view(gradient.shape[0], -1)\n    gradient_norm = gradient.norm(2, dim=1)\n    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n    return gradient_penalty","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:02.440887Z","iopub.execute_input":"2022-04-06T11:00:02.441443Z","iopub.status.idle":"2022-04-06T11:00:02.451578Z","shell.execute_reply.started":"2022-04-06T11:00:02.4414Z","shell.execute_reply":"2022-04-06T11:00:02.450782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_losses = []\ndisc_losses = []\n\nfor epoch in range(epochs):\n    start = time.time()\n    for i, data in enumerate(data_loader, 0):\n\n        ###TRAIN DISCRIMINATOR\n        #Put the real images on the GPU\n        real = data[0].to(device)\n        #Iterate\n        for _ in range(critic_iterations):\n        #Generate fake images for later use\n            size = real.size(0)\n            noise = torch.randn(size, noise_dim, 1, 1, device=device)\n            fake = generator(noise)\n            label = torch.full((size,), 1, device=device, dtype=torch.float)\n            output_real = discriminator(real).view(-1)  \n            real_mean = output_real.mean().item()\n            label.fill_(0)\n            output_fake = discriminator(fake.detach()).view(-1)\n            fake_mean = output_fake.mean().item()\n            gp = gradient_penalty(discriminator, real, fake, device)\n            disc_err = (-(torch.mean(output_real) - torch.mean(output_fake))+lambda_gp*gp)\n            # Zero out gradients prior to backward passes\n            discriminator.zero_grad()    \n            disc_err.backward(retain_graph=True)\n            disc_optimizer.step()\n            \n        # TRAIN THE GENERATOR\n        # Discriminate on fake with updated discriminator\n        label.fill_(1)\n        output = discriminator(fake).view(-1)\n        gen_mean = output.mean().item()\n        # Calculate loss on fake\n        gen_err = -torch.mean(output)\n        generator.zero_grad()\n        gen_err.backward()\n        gen_optimizer.step()\n        \n        if epoch % 1000 == 0:\n            print('[%d/%d][%d/%d] \\tD-Loss:%.4f\\t G-Loss:%.4f\\t D(x):%.4f\\t D(G(z)):%.4f\\t G(z):%.4f' \n                  % (epoch + 1, epochs, i + 1, len(data_loader), disc_err.item(), gen_err.item(), real_mean, fake_mean, gen_mean))\n            \n        gen_losses.append(gen_err.item())\n        disc_losses.append(disc_err.item())\n        \n    end = time.time()\n    timedelta = datetime.timedelta(seconds=int(end - start))\n    if epoch % 500 == 0: print(f'Time elapsed for epoch {epoch + 1}: {timedelta}\\n')\n    with torch.no_grad():\n        sample = generator(sample_noise).detach().cpu()\n    grid = np.transpose(utils.make_grid(sample, padding=4, normalize=True).cpu(), (1, 2, 0))\n    \n\n    \n    if epoch % 1000 == 0:\n        # Generate loss graph\n        plt.figure(figsize=(8, 8))\n        plt.axis('off')\n        plt.imshow(grid)\n        plt.savefig(os.path.join(figures_dir, f'epoch_{epoch + 1}.png'))\n        plt.close()\n        \n        with open(\"d_losses.txt\",'a',encoding = 'utf-8') as fd:\n           fd.write(str(disc_losses[-1]) +\"\\n\")\n        with open(\"g_losses.txt\",'a',encoding = 'utf-8') as fg:\n           fg.write(str(gen_losses[-1]) +\"\\n\")\n        \n        \n        # Save progress\n        torch.save(generator, os.path.join(checkpoints_dir, f'generator_new{epoch}.pt'))\n        torch.save(discriminator, os.path.join(checkpoints_dir, f'discriminator_new{epoch}.pt'))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:02.453066Z","iopub.execute_input":"2022-04-06T11:00:02.453541Z","iopub.status.idle":"2022-04-06T11:00:14.98524Z","shell.execute_reply.started":"2022-04-06T11:00:02.4535Z","shell.execute_reply":"2022-04-06T11:00:14.98439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"epoch.txt\",'w',encoding = 'utf-8') as fe:\n   fe.write(str(epoch+1) +\"\\n\")\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-06T11:00:14.986703Z","iopub.execute_input":"2022-04-06T11:00:14.986996Z","iopub.status.idle":"2022-04-06T11:00:14.992592Z","shell.execute_reply.started":"2022-04-06T11:00:14.986959Z","shell.execute_reply":"2022-04-06T11:00:14.991703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clear CUDA cache if needed","metadata":{}},{"cell_type":"markdown","source":"Plot the loss graph","metadata":{}},{"cell_type":"markdown","source":"Generate samples on random noise","metadata":{}},{"cell_type":"markdown","source":"<a href=\"BM1.zip\"> Download File </a>","metadata":{}},{"cell_type":"markdown","source":"<a href=\"working.zip\"> Download File </a>","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}